ğŸ“Š Etapa 1 â€” AnÃ¡lise ExploratÃ³ria de Dados (EDA)

Projeto de Machine Learning â€“ Entendimento dos Dados

ğŸ¯ VisÃ£o Geral

Na Etapa 1, o objetivo foi explorar, compreender e visualizar o dataset bruto para identificar problemas, padrÃµes, distribuiÃ§Ãµes e relaÃ§Ãµes entre variÃ¡veis.
Essa fase Ã© fundamental para orientar o que serÃ¡ feito no prÃ©-processamento (Etapa 2) e na modelagem (Etapa 3).

Todo o trabalho foi documentado no notebook:
ğŸ“ notebooks/01_Analise_Exploratoria.ipynb

ğŸ“ Tarefas Realizadas
1ï¸âƒ£ Carregamento e InspeÃ§Ã£o Inicial
âœ”ï¸ O que foi feito:

Carregamento do dataset bruto.

VisualizaÃ§Ã£o das primeiras linhas e dos tipos de dados.

AnÃ¡lise de:

NÃºmero de linhas e colunas

Tipos das variÃ¡veis (numÃ©ricas, categÃ³ricas, datas, texto)

EstatÃ­sticas gerais com .describe()

ğŸ¯ Objetivo: entender a estrutura do dataset e identificar possÃ­veis problemas logo de inÃ­cio.

2ï¸âƒ£ AnÃ¡lise de Valores Faltantes
âœ”ï¸ O que foi feito:

IdentificaÃ§Ã£o de colunas com valores ausentes (NaN).

QuantificaÃ§Ã£o do total de valores faltantes por coluna e porcentagem afetada.

VisualizaÃ§Ã£o grÃ¡fica (quando necessÃ¡rio) para destacar gravidade e impacto.

ğŸ¯ ImportÃ¢ncia: valores faltantes serÃ£o tratados apenas na Etapa 2, mas aqui foi fundamental detectar onde, quanto e por quÃª isso acontece.

3ï¸âƒ£ AnÃ¡lise EstatÃ­stica das VariÃ¡veis NumÃ©ricas
âœ”ï¸ O que foi feito:

Histograma para cada variÃ¡vel numÃ©rica.

Boxplots para identificaÃ§Ã£o de:

DistribuiÃ§Ã£o

Assimetria

PresenÃ§a de outliers

CÃ¡lculo de medidas importantes:

MÃ©dia

Mediana

Desvio padrÃ£o

Quartis

ğŸ¯ Objetivo: entender o comportamento das variÃ¡veis, localizar outliers e possÃ­veis transformaÃ§Ãµes necessÃ¡rias.

4ï¸âƒ£ AnÃ¡lise das VariÃ¡veis CategÃ³ricas
âœ”ï¸ O que foi feito:

Contagem de categorias (value_counts).

GrÃ¡ficos de barras mostrando a frequÃªncia de cada categoria.

VerificaÃ§Ã£o da qualidade das categorias:

InconsistÃªncias

Categorias muito raras

Erros de digitaÃ§Ã£o

ğŸ¯ Objetivo: mapear categorias antes de aplicar encoding na Etapa 2.

5ï¸âƒ£ CorrelaÃ§Ã£o Entre VariÃ¡veis
âœ”ï¸ O que foi feito:

Matriz de correlaÃ§Ã£o entre variÃ¡veis numÃ©ricas.

Heatmap para visualizar relaÃ§Ãµes fortes e fracas.

IdentificaÃ§Ã£o de:

VariÃ¡veis redundantes

PossÃ­veis features importantes para o modelo

ğŸ¯ Objetivo: entender como variÃ¡veis se relacionam entre si e prever impacto na modelagem.

6ï¸âƒ£ GeraÃ§Ã£o dos GrÃ¡ficos Principais (somente os mais importantes)

O professor pediu apenas os grÃ¡ficos essenciais, entÃ£o os principais incluÃ­dos foram:

ğŸ“ˆ Histograma de variÃ¡veis mais relevantes

ğŸ“¦ Boxplot destacando outliers importantes

ğŸ“Š GrÃ¡fico de barras das categorias mais significativas

ğŸ”¥ Heatmap com as correlaÃ§Ãµes principais

ğŸ¯ Esses grÃ¡ficos serviram para comprovar visualmente que a exploraÃ§Ã£o foi realizada corretamente.

ğŸ“ EntregÃ¡veis
Arquivo	DescriÃ§Ã£o
ğŸ““ notebooks/01_Analise_Exploratoria.ipynb	Notebook completo com anÃ¡lises e grÃ¡ficos
ğŸ“ data/raw/*	Dataset bruto utilizado
ğŸ¤ ApresentaÃ§Ã£o (4â€“5 Minutos)
ğŸ–¼ï¸ Slide 1 â€” VisÃ£o Geral do Dataset

Quantidade de linhas e colunas

Tipos de variÃ¡veis

ğŸ§© Slide 2 â€” Problemas Identificados

Valores faltantes

Outliers

InconsistÃªncias

ğŸ“Š Slide 3 â€” Principais GrÃ¡ficos

Histogramas essenciais

Boxplot mais relevante

Heatmap de correlaÃ§Ãµes

ğŸ“Œ Slide 4 â€” ConclusÃ£o

O que foi aprendido sobre os dados

PreparaÃ§Ã£o para Etapa 2 (limpeza e transformaÃ§Ã£o)

âœ… Checklist de Sucesso

 Dataset carregado e analisado com clareza

 Valores faltantes identificados

 Outliers mapeados

 VariÃ¡veis categÃ³ricas entendidas

 CorrelaÃ§Ãµes visualizadas

 GrÃ¡ficos principais gerados e revisados

ğŸš€ ConclusÃ£o

A Etapa 1 forneceu entendimento profundo dos dados, revelando problemas e padrÃµes cruciais para o prÃ©-processamento.
Agora, com essa anÃ¡lise completa, foi possÃ­vel seguir para a Etapa 2 com seguranÃ§a, limpando e preparando os dados da forma correta.

ğŸ“¦ Etapa 2 â€” PrÃ©-Processamento de Dados
Projeto de Machine Learning â€“ PreparaÃ§Ã£o dos Dados

ğŸ¯ VisÃ£o Geral
Nesta etapa, realizamos a limpeza, transformaÃ§Ã£o e padronizaÃ§Ã£o dos dados brutos analisados na Etapa 1.
O objetivo Ã© deixar o dataset pronto para treinar modelos de Machine Learning, garantindo qualidade, consistÃªncia e formato adequado.
Todo o trabalho desta etapa estÃ¡ documentado no notebook:
ğŸ“ notebooks/02_Preprocessamento.ipynb

ğŸ“ Tarefas Realizadas
1ï¸âƒ£ Tratamento de Valores Faltantes
Por que fazer isso?
â¡ï¸ Algoritmos de Machine Learning nÃ£o lidam com NaN. Deixar valores faltantes gera erros e prejudica o modelo.
âœ”ï¸ O que foi feito:


Colunas numÃ©ricas: valores imputados usando mediana (mais segura contra outliers).

Colunas categÃ³ricas: preenchimento com a categoria mais frequente.

2ï¸âƒ£ Tratamento de Outliers
Por que fazer isso?
â¡ï¸ Outliers distorcem escalas, atrapalham modelos lineares e podem influenciar negativamente os resultados.
âœ”ï¸ O que foi feito:


Outliers foram identificados com base na anÃ¡lise da Etapa 1.


Aplicada a tÃ©cnica de capping (limite pelo IQR) para reduzir impacto sem remover dados importantes.


RemoÃ§Ã£o apenas de valores claramente incorretos (quando identificado como erro de digitaÃ§Ã£o/mediÃ§Ã£o).



3ï¸âƒ£ Encoding de VariÃ¡veis CategÃ³ricas
Por que fazer isso?
â¡ï¸ Modelos de ML nÃ£o entendem texto. Precisamos converter para nÃºmeros.
âœ”ï¸ O que foi feito:


One-Hot Encoding aplicado para variÃ¡veis categÃ³ricas nominais.


Utilizado drop_first=True para evitar multicolinearidade.


VariÃ¡veis com ordem natural (ordinais) foram codificadas com mapeamento numÃ©rico apropriado.



4ï¸âƒ£ NormalizaÃ§Ã£o das VariÃ¡veis NumÃ©ricas
Por que fazer isso?
â¡ï¸ Colunas em escalas muito diferentes podem fazer o modelo priorizar algumas features sem necessidade.
âœ”ï¸ O que foi feito:


Aplicado StandardScaler (mÃ©dia 0 e desvio padrÃ£o 1) apÃ³s limpeza completa.


O scaler foi salvo para uso futuro:
ğŸ“ models/scaler.pkl



5ï¸âƒ£ Feature Engineering (Opcional)
Por que fazer isso?
â¡ï¸ Novas features podem ajudar o modelo a aprender padrÃµes mais profundos.
âœ”ï¸ O que foi criado:


Features derivadas de relaÃ§Ãµes entre variÃ¡veis (exemplo: velocidade mÃ©dia, razÃµes entre colunas etc. â€” adapte conforme seu projeto).


Cada feature criada foi documentada e justificada no notebook.



ğŸ“Š EntregÃ¡veis Principais
ArquivoDescriÃ§Ã£oğŸ““ notebooks/02_Preprocessamento.ipynbCÃ³digo + explicaÃ§Ãµes da etapağŸ“ data/students_clean.csvDataset final tratadoâš™ï¸ models/scaler.pklScaler salvo para uso na modelagem

ğŸ¤ ApresentaÃ§Ã£o (4â€“5 Minutos)
ğŸ–¼ï¸ Slide 1 â€” Problemas Corrigidos


Quantidade de valores faltantes tratados


Outliers identificados e qual estratÃ©gia foi usada


ğŸ§© Slide 2 â€” Principais TransformaÃ§Ãµes


Exemplo de One-Hot Encoding


ComparaÃ§Ã£o de variÃ¡veis antes/depois da normalizaÃ§Ã£o


ğŸ› ï¸ Slide 3 â€” Feature Engineering


Novas features criadas


MotivaÃ§Ã£o e impacto esperado


ğŸ“Š Slide 4 â€” Resultado Final


DimensÃµes antes e depois


ConfirmaÃ§Ã£o de que o dataset estÃ¡ pronto para modelagem



âœ… Checklist de Sucesso


 Notebook organizado com seÃ§Ãµes claras


 Justificativas detalhadas em Markdown


 Dataset final salvo corretamente


 Scaler salvo em models/scaler.pkl


 Notebook executa do inÃ­cio ao fim sem erros


ğŸš€ ConclusÃ£o
A Etapa 2 garante que os dados estejam consistentes, completos e padronizados â€” prontos para avanÃ§armos para a etapa de modelagem na fase 3!