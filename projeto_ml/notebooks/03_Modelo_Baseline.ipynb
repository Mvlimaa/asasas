{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd86690e",
   "metadata": {},
   "source": [
    "notebooks/03_Modelo_Baseline.ipynb\n",
    "------------------------------------------\n",
    "1. IMPORTS\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27983e",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    " 2. CARREGAR DADOS LIMPOS\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ETAPA 3: MODELO BASELINE - REGRESSÃƒO LINEAR (DELIVERY)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Caminho correto para o arquivo limpo gerado na Etapa 2\n",
    "caminho_dados = '../data/processed/delivery_clean.csv'\n",
    "\n",
    "if not os.path.exists(caminho_dados):\n",
    "    print(f\"âš ï¸ ARQUIVO NÃƒO ENCONTRADO: {caminho_dados}\")\n",
    "    print(\"Verifique se vocÃª rodou a Etapa 2 e salvou o CSV.\")\n",
    "else:\n",
    "    df = pd.read_csv(caminho_dados)\n",
    "    print(f\"\\nâœ“ Dados carregados: {df.shape[0]} linhas, {df.shape[1]} colunas\\n\")\n",
    "    \n",
    "    # Exibir com formataÃ§Ã£o melhorada\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(df.head().to_string())\n",
    "    print(f\"\\nðŸ“‹ Tipos de dados:\\n{df.dtypes.to_string()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e25cd",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    " 3. SEPARAR FEATURES (X) e TARGET (Y)\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target do seu projeto de entrega\n",
    "TARGET_COLUMN = 'delivery_time_hours' \n",
    "\n",
    "# Colunas que nÃ£o sÃ£o Ãºteis para previsÃ£o (IDs, etc)\n",
    "COLUNAS_REMOVER = ['delivery_id'] \n",
    "\n",
    "# Garantir que removemos apenas o que existe no df\n",
    "cols_to_drop = [c for c in COLUNAS_REMOVER if c in df.columns] + [TARGET_COLUMN]\n",
    "\n",
    "X = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "print(f\"\\nâœ“ Features (X): {X.shape[1]} colunas\")\n",
    "print(f\"âœ“ Target (y): {y.shape[0]} valores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922cab99",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    " - 3.5 CODIFICAR VARIÃVEIS CATEGÃ“RICAS)\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3792c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CODIFICANDO VARIÃVEIS CATEGÃ“RICAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identificar colunas categÃ³ricas\n",
    "colunas_categoricas = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Colunas categÃ³ricas encontradas: {colunas_categoricas}\")\n",
    "\n",
    "# Usar One-Hot Encoding\n",
    "if len(colunas_categoricas) > 0:\n",
    "    X = pd.get_dummies(X, columns=colunas_categoricas, drop_first=True)\n",
    "    print(f\"âœ“ One-Hot Encoding aplicado!\")\n",
    "    print(f\"âœ“ Novas features (X): {X.shape[1]} colunas\")\n",
    "\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032c4ea",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    " - 3.6 TRATAR VALORES FALTANTES (NaN)\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a239a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRATANDO VALORES FALTANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar NaN\n",
    "print(f\"NaN por coluna:\\n{X.isnull().sum()}\")\n",
    "print(f\"\\nTotal de NaN: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# OpÃ§Ã£o 1: Remover linhas com NaN\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"Removendo linhas com valores faltantes...\")\n",
    "    X = X.dropna()\n",
    "    y = y[X.index]  # Sincronizar y com X\n",
    "    print(f\"âœ“ ApÃ³s remoÃ§Ã£o: {X.shape[0]} linhas\")\n",
    "\n",
    "# OpÃ§Ã£o 2 (alternativa): Preencher com mÃ©dia (descomente se preferir)\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(f\"âœ“ NaN remanescentes: {X.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca072350",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    " 4. DIVISÃƒO DOS DADOS (60% TREINO / 20% VALIDAÃ‡ÃƒO / 20% TESTE)\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94149d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# 1. Separar 20% para TESTE (Guardar no cofre!)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 2. Separar 25% do restante para VALIDAÃ‡ÃƒO (25% de 80% = 20% do total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIVISÃƒO DOS DADOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total: {len(X)}\")\n",
    "print(f\"â”œâ”€ Treino:     {len(X_train)} (60%)\")\n",
    "print(f\"â”œâ”€ ValidaÃ§Ã£o:  {len(X_val)} (20%)\")\n",
    "print(f\"â””â”€ Teste:      {len(X_test)} (20%) - NÃƒO USAR AGORA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec4a45",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "5. TREINAR MODELO BASELINE\n",
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TREINAMENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "print(\"âœ“ Modelo de RegressÃ£o Linear treinado!\")\n",
    "\n",
    "# Analisar os coeficientes (O que mais impacta a entrega?)\n",
    "coeficientes = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coeficiente': modelo.coef_\n",
    "}).sort_values('Coeficiente', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 VariÃ¡veis Mais Impactantes:\")\n",
    "print(coeficientes.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77374dd1",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "6. AVALIAÃ‡ÃƒO E MÃ‰TRICAS\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrevisÃµes\n",
    "y_train_pred = modelo.predict(X_train)\n",
    "y_val_pred = modelo.predict(X_val)\n",
    "\n",
    "def calcular_metricas(y_true, y_pred, nome):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'RÂ²': r2}\n",
    "\n",
    "metricas_train = calcular_metricas(y_train, y_train_pred, \"Treino\")\n",
    "metricas_val = calcular_metricas(y_val, y_val_pred, \"ValidaÃ§Ã£o\")\n",
    "\n",
    "# Exibir ComparaÃ§Ã£o\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTADOS (Treino vs ValidaÃ§Ã£o)\")\n",
    "print(\"=\"*60)\n",
    "df_metricas = pd.DataFrame([metricas_train, metricas_val], index=['Treino', 'ValidaÃ§Ã£o'])\n",
    "print(df_metricas.round(4))\n",
    "\n",
    "# AnÃ¡lise de Overfitting (RÂ²)\n",
    "diff_r2 = abs(df_metricas.loc['Treino', 'RÂ²'] - df_metricas.loc['ValidaÃ§Ã£o', 'RÂ²'])\n",
    "print(f\"\\nðŸ“Š AnÃ¡lise de Overfitting (DiferenÃ§a RÂ²): {diff_r2:.4f}\")\n",
    "if diff_r2 < 0.10:\n",
    "    print(\"âœ… SUCESSO: O modelo generaliza bem (sem overfitting grave).\")\n",
    "else:\n",
    "    print(\"âš ï¸ ATENÃ‡ÃƒO: Sinal de overfitting (diferenÃ§a > 0.10).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8745f45",
   "metadata": {},
   "source": [
    "\n",
    "----------------------------------\n",
    "7. VISUALIZAÃ‡Ã•ES\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGerando grÃ¡ficos...\")\n",
    "\n",
    "# GrÃ¡fico 1: Predito vs Real\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.5)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "plt.xlabel('Real (Horas)')\n",
    "plt.ylabel('Previsto (Horas)')\n",
    "plt.title(f'Predito vs Real (ValidaÃ§Ã£o) - RÂ²: {metricas_val[\"RÂ²\"]:.2f}')\n",
    "plt.savefig('../models/predicoes_vs_real.png')\n",
    "plt.show()\n",
    "\n",
    "# GrÃ¡fico 2: ResÃ­duos\n",
    "residuos = y_val - y_val_pred\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(residuos, kde=True, bins=30)\n",
    "plt.axvline(0, color='r', linestyle='--')\n",
    "plt.title('DistribuiÃ§Ã£o dos ResÃ­duos (Erros)')\n",
    "plt.xlabel('Erro (Real - Previsto)')\n",
    "plt.savefig('../models/residuos.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072796f",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "8. SALVAR MODELO\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(modelo, '../models/baseline_model.pkl')\n",
    "print(\"\\nâœ“ Modelo salvo em ../models/baseline_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1800500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
