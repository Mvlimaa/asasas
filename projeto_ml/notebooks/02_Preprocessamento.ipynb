{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ebd3e0",
   "metadata": {},
   "source": [
    "# 02_Preprocessamento.ipynb\n",
    "---------------------------------\n",
    "1. Imports e Configura√ß√µes\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cf320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 2 ‚Äî CORRIGIR CAMINHOS\n",
    "\n",
    "RAW = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\raw\\delivery_time.csv\"\n",
    "CLEAN = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\processed\\delivery_clean.csv\"\n",
    "SCALED = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\processed\\delivery_processed.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c3fb2",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "2. Caminhos dos Arquivos + Carregar arquivos\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d901bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\raw\\delivery_time.csv\"\n",
    "CLEAN = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\processed\\delivery_clean.csv\"\n",
    "SCALED = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\processed\\delivery_processed.csv\"\n",
    "\n",
    "# carregar raw (erro se faltar ‚Äî arquivo raw √© obrigat√≥rio)\n",
    "if not os.path.exists(RAW):\n",
    "    raise FileNotFoundError(f\"Arquivo RAW n√£o encontrado: {RAW}\")\n",
    "df_raw = pd.read_csv(RAW)\n",
    "\n",
    "# carregar clean/processed se existirem; caso contr√°rio criar c√≥pias a partir do raw\n",
    "if os.path.exists(CLEAN):\n",
    "    df_clean = pd.read_csv(CLEAN)\n",
    "else:\n",
    "    print(\"WARNING: arquivo CLEAN n√£o encontrado ‚Äî usando c√≥pia de raw como df_clean (execute c√©lulas de preprocessamento).\")\n",
    "    df_clean = df_raw.copy()\n",
    "\n",
    "if os.path.exists(SCALED):\n",
    "    df_scaled = pd.read_csv(SCALED)\n",
    "else:\n",
    "    print(\"WARNING: arquivo SCALED n√£o encontrado ‚Äî usando df_clean como df_scaled (execute pr√©-processamento).\")\n",
    "    df_scaled = df_clean.copy()\n",
    "\n",
    "print(\"Shapes ‚Äî raw:\", df_raw.shape, \"clean:\", df_clean.shape, \"scaled:\", df_scaled.shape)\n",
    "display(df_raw.head())\n",
    "display(df_clean.head())\n",
    "display(df_scaled.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b30fa",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "4. Verificar Valores Negativos\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = [\n",
    "    \"distance_km\",\n",
    "    \"package_weight_kg\",\n",
    "    \"driver_experience_years\",\n",
    "    \"num_stops\",\n",
    "    \"customer_rating\",\n",
    "    \"fuel_cost\",\n",
    "    \"delivery_time_hours\"\n",
    "]\n",
    "\n",
    "for col in cols_to_check:\n",
    "    neg_count = (df_clean[col] < 0).sum()\n",
    "    if neg_count > 0:\n",
    "        print(f\"‚ö†Ô∏è {col} possui {neg_count} valores negativos!\")\n",
    "    else:\n",
    "        print(f\"‚úîÔ∏è {col} est√° sem valores negativos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646366c",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "5. Gr√°fico de Compara√ß√£o (Raw vs Clean vs Scaled)\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"distance_km\"  \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.kdeplot(df_raw[col], label=\"Raw (etapa 1)\", fill=True)\n",
    "sns.kdeplot(df_clean[col], label=\"Clean (etapa 2)\", fill=True)\n",
    "sns.kdeplot(df_scaled[col], label=\"Scaled (etapa 3)\", fill=True)\n",
    "\n",
    "plt.title(f\"Compara√ß√£o de Distribui√ß√µes ‚Äî {col}\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62061d67",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "6. Resolver Valores Negativos\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diret√≥rio se n√£o existir\n",
    "os.makedirs(os.path.dirname(CLEAN), exist_ok=True)\n",
    "\n",
    "for col in [\"distance_km\", \"package_weight_kg\"]:\n",
    "    df_clean[col] = df_clean[col].abs()\n",
    "\n",
    "df_clean.to_csv(CLEAN, index=False)\n",
    "print(\"Valores negativos corrigidos e arquivo salvo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67720323",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "7. Revalidar Ap√≥s a Corre√ß√£o\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# usa cols_fix se definida; caso contr√°rio tenta cols_to_check; sen√£o usa todas as num√©ricas em df_clean\n",
    "cols_fix = globals().get('cols_fix') or globals().get('cols_to_check')\n",
    "if cols_fix is None:\n",
    "    cols_fix = [c for c in df_clean.select_dtypes(include=[np.number]).columns.tolist()]\n",
    "\n",
    "print(\"Revalidando colunas:\", cols_fix)\n",
    "for col in cols_fix:\n",
    "    if col not in df_clean.columns:\n",
    "        print(f\"‚ö†Ô∏è Coluna '{col}' n√£o encontrada em df_clean ‚Äî pulando.\")\n",
    "        continue\n",
    "    neg_remaining = (df_clean[col] < 0).sum()\n",
    "    print(f\"{col}: negativos restantes = {neg_remaining}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73acf62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 7.5 ‚Äî Criar arquivo SCALED com StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Definir colunas num√©ricas para escalar\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Criar c√≥pia para escalar\n",
    "df_scaled = df_clean.copy()\n",
    "\n",
    "# Criar e ajustar o scaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])\n",
    "\n",
    "# Criar diret√≥rios se n√£o existirem\n",
    "os.makedirs(os.path.dirname(SCALED), exist_ok=True)\n",
    "os.makedirs(r\"C:\\Users\\levie\\asasas\\projeto_ml\\models\", exist_ok=True)\n",
    "\n",
    "# Salvar arquivos\n",
    "df_scaled.to_csv(SCALED, index=False)\n",
    "joblib.dump(scaler, r\"C:\\Users\\levie\\asasas\\projeto_ml\\models\\scaler.pkl\")\n",
    "\n",
    "# Salvar metadata\n",
    "meta = {\"numeric_to_scale\": numeric_cols}\n",
    "joblib.dump(meta, r\"C:\\Users\\levie\\asasas\\projeto_ml\\models\\preprocess_meta.pkl\")\n",
    "\n",
    "print(\"‚úîÔ∏è Arquivo SCALED salvo!\")\n",
    "print(\"‚úîÔ∏è Scaler salvo em models/scaler.pkl\")\n",
    "print(\"‚úîÔ∏è Metadata salvo em models/preprocess_meta.pkl\")\n",
    "print(\"Colunas escaladas:\", numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fd0de",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "8. Gr√°fico de Compara√ß√£o Ap√≥s Corre√ß√£o\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee866452",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"distance_km\" \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.kdeplot(df_raw[col], label=\"Raw (etapa 1)\", fill=True)\n",
    "sns.kdeplot(df_clean[col], label=\"Clean corrigido (etapa 2)\", fill=True)\n",
    "sns.kdeplot(df_scaled[col], label=\"Scaled (etapa 3)\", fill=True)\n",
    "\n",
    "plt.title(f\"Distribui√ß√£o ‚Äî RAW vs CLEAN CORRIGIDO vs SCALED ‚Äî {col}\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9c780",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "9. Mostrar Estat√≠sticas das Tr√™s Vers√µes\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15254973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 09 ‚Äî Estat√≠sticas principais\n",
    "pd.DataFrame({\n",
    "    \"Raw\": df_raw.describe().iloc[1],\n",
    "    \"Clean Corrigido\": df_clean.describe().iloc[1],\n",
    "    \"Scaled\": df_scaled.describe().iloc[1]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843a6f2",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "10. Teste Scaler\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7714ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# üîé C√âLULA √öNICA ‚Äî DIAGN√ìSTICO COMPLETO DO SCALER\n",
    "# ===========================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "RAW = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\raw\\delivery_time.csv\"\n",
    "OUT_CLEAN = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\processed\\delivery_clean.csv\"\n",
    "OUT_PROCESSED = r\"C:\\Users\\levie\\asasas\\projeto_ml\\data\\processed\\delivery_processed.csv\"\n",
    "SCALER_PATH = r\"C:\\Users\\levie\\asasas\\projeto_ml\\models\\scaler.pkl\"\n",
    "META_PATH = r\"C:\\Users\\levie\\asasas\\projeto_ml\\models\\preprocess_meta.pkl\" \n",
    "\n",
    "# --- coluna que voc√™ quer diagnosticar\n",
    "col = \"distance_km\"     # üëà TROQUE AQUI\n",
    "\n",
    "# --- carregar dados e objetos\n",
    "df_raw = pd.read_csv(RAW)\n",
    "df_clean = pd.read_csv(OUT_CLEAN)\n",
    "df_processed = pd.read_csv(OUT_PROCESSED)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "meta = joblib.load(META_PATH)\n",
    "\n",
    "numeric_to_scale = meta.get(\"numeric_to_scale\", [])\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"üìå INFORMA√á√ïES INICIAIS\")\n",
    "print(\"==============================\")\n",
    "print(\"Coluna analisada:\", col)\n",
    "print(\"Colunas escaladas:\", numeric_to_scale)\n",
    "print(\"Existe no processed:\", col in df_processed.columns)\n",
    "\n",
    "if col not in df_raw.columns:\n",
    "    print(f\"\\n‚ùå ERRO: coluna {col} n√£o existe no RAW. Verifique o nome.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "if col not in df_clean.columns:\n",
    "    print(f\"\\n‚ùå ERRO: coluna {col} n√£o existe no CLEAN. Verifique o nome.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# =======================================================\n",
    "# TESTE 1 ‚Äî Estat√≠sticas antes/depois\n",
    "# =======================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"üìä TESTE 1 ‚Äî Estat√≠sticas RAW vs CLEAN vs PROCESSED\")\n",
    "print(\"==============================\")\n",
    "\n",
    "orig = df_clean[col]\n",
    "proc = df_processed[col] if col in df_processed.columns else None\n",
    "\n",
    "print(\"RAW   ‚Üí min / median / mean / max:\", \n",
    "      df_raw[col].min(), df_raw[col].median(), df_raw[col].mean(), df_raw[col].max())\n",
    "print(\"CLEAN ‚Üí min / median / mean / max:\", \n",
    "      orig.min(), orig.median(), orig.mean(), orig.max())\n",
    "\n",
    "if proc is not None:\n",
    "    print(\"PROC  ‚Üí min / median / mean / max:\",\n",
    "          proc.min(), proc.median(), proc.mean(), proc.max())\n",
    "else:\n",
    "    print(\"PROC  ‚Üí coluna n√£o est√° no df_processed (poss√≠vel one-hot).\")\n",
    "\n",
    "# =======================================================\n",
    "# TESTE 2 ‚Äî Plotar distribui√ß√µes\n",
    "# =======================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"üìà TESTE 2 ‚Äî Gr√°ficos de Distribui√ß√£o\")\n",
    "print(\"==============================\")\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(orig.dropna(), kde=True)\n",
    "plt.title(f\"CLEAN ‚Äî {col}\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "if proc is not None:\n",
    "    sns.histplot(proc.dropna(), kde=True)\n",
    "    plt.title(f\"PROCESSED (scaled) ‚Äî {col}\")\n",
    "else:\n",
    "    plt.text(0.3, 0.5, \"Coluna n√£o est√° no processed\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# =======================================================\n",
    "# TESTE 3 ‚Äî Verificar se virou one-hot (dummies)\n",
    "# =======================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"üß© TESTE 3 ‚Äî Verificando se a coluna virou dummies\")\n",
    "print(\"==============================\")\n",
    "\n",
    "related = [c for c in df_processed.columns if c.startswith(col + \"_\")]\n",
    "if len(related) > 0:\n",
    "    print(\"A coluna original virou as seguintes dummies:\")\n",
    "    print(related)\n",
    "else:\n",
    "    print(\"Nenhuma dummy encontrada ‚Äî √© uma coluna num√©rica normal.\")\n",
    "\n",
    "# =======================================================\n",
    "# TESTE 4 ‚Äî Invers√£o do scaling\n",
    "# =======================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"üîÑ TESTE 4 ‚Äî Invers√£o do StandardScaler\")\n",
    "print(\"==============================\")\n",
    "\n",
    "if col in numeric_to_scale:\n",
    "    idx = numeric_to_scale.index(col)\n",
    "    scaled_vals = df_processed[col].to_numpy()\n",
    "    inv = scaled_vals * scaler.scale_[idx] + scaler.mean_[idx]\n",
    "\n",
    "    print(\"Valores invertidos (min/median/max):\",\n",
    "          np.nanmin(inv), np.nanmedian(inv), np.nanmax(inv))\n",
    "else:\n",
    "    print(\"A coluna N√ÉO est√° em numeric_to_scale ‚Üí n√£o passou pelo scaler.\")\n",
    "\n",
    "# =======================================================\n",
    "# DIAGN√ìSTICO FINAL\n",
    "# =======================================================\n",
    "print(\"\\n==============================\")\n",
    "print(\"üß† DIAGN√ìSTICO FINAL\")\n",
    "print(\"==============================\")\n",
    "\n",
    "dummy_flag = len(related) > 0\n",
    "scaled_flag = col in numeric_to_scale\n",
    "\n",
    "if dummy_flag:\n",
    "    print(\"‚úî A coluna virou v√°rias colunas one-hot ‚ö†Ô∏è\")\n",
    "    print(\"Picos altos s√£o NORMAIS em distribui√ß√µes one-hot + scaler.\")\n",
    "elif not scaled_flag and col in df_processed:\n",
    "    print(\"‚ö† A coluna existe no processed mas N√ÉO est√° na lista numeric_to_scale.\")\n",
    "    print(\"Isso pode gerar comportamento estranho no gr√°fico.\")\n",
    "elif scaled_flag:\n",
    "    print(\"‚úî A coluna foi escalada corretamente.\")\n",
    "    print(\"Se existe pico, provavelmente √©:\")\n",
    "    print(\"- distribui√ß√£o muito concentrada (normal);\")\n",
    "    print(\"- valores discretos;\")\n",
    "    print(\"- ou outliers que foram limitados.\")\n",
    "else:\n",
    "    print(\"‚ùå Algo est√° inconsistente: coluna n√£o aparece no processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
