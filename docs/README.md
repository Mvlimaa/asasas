ğŸ“˜ Projeto de Machine Learning â€“ PrevisÃ£o de Tempo de Entrega
ğŸ‘¥ Integrantes do Projeto

JoÃ£o Levi Bezerra da Silva - 01735303
Marcelo Vynicius de Lima Silva - 01700876
Fernando AntÃ´nio da Silva Neto - 01703313

ğŸ“‚ Dataset Utilizado

Nome: delivery_time.csv
DescriÃ§Ã£o: ContÃ©m dados de entregas (distÃ¢ncia, clima, veÃ­culo, peso, condiÃ§Ãµes de trÃ¡fego etc.) utilizados para prever o tempo total de entrega em horas.

ğŸ“Š Etapa 1 â€” AnÃ¡lise ExploratÃ³ria (EDA)

Objetivo: entender o dataset, problemas, padrÃµes e estrutura inicial.

âœ”ï¸ O que foi feito

InspeÃ§Ã£o inicial (linhas, colunas, tipos, estatÃ­sticas).

IdentificaÃ§Ã£o de valores faltantes.

Histogramas e boxplots para variÃ¡veis numÃ©ricas.

FrequÃªncias e inconsistÃªncias para variÃ¡veis categÃ³ricas.

Heatmap de correlaÃ§Ã£o.

GrÃ¡ficos essenciais solicitados pelo professor.

ğŸ“ EntregÃ¡vel: notebooks/01_Analise_Exploratoria.ipynb

-------------------------------------------------------------

ğŸ§¹ Etapa 2 â€” PrÃ©-Processamento dos Dados

Objetivo: limpar e preparar os dados para modelagem.

âœ”ï¸ O que foi feito

Valores faltantes:

NumÃ©ricos â†’ mediana

CategÃ³ricos â†’ moda

Outliers:

Tratamento via IQR (capping)

CorreÃ§Ã£o de valores incoerentes

Encoding:

One-Hot Encoding (drop_first=True)

NormalizaÃ§Ã£o:

StandardScaler aplicado Ã s colunas numÃ©ricas

Scaler salvo em models/scaler.pkl

Feature Engineering:

CriaÃ§Ã£o de features simples derivadas

ğŸ“ EntregÃ¡veis:

notebooks/02_Preprocessamento.ipynb

data/delivery_clean.csv

models/scaler.pkl

-------------------------------------------------------------

ğŸ¤– Etapa 3 â€” Modelo Baseline (RegressÃ£o Linear)

Objetivo: criar o primeiro modelo para servir de referÃªncia.

âœ”ï¸ O que foi feito

Uso do dataset delivery_clean.csv sem NaN

Target: delivery_time_hours

RemoÃ§Ã£o de IDs e colunas irrelevantes

One-Hot Encoding nas categÃ³ricas

RemoÃ§Ã£o de NaN restantes apÃ³s encoding

DivisÃ£o dos dados:

60% treino

20% validaÃ§Ã£o

20% teste (guardado)

Treinamento:

Modelo: RegressÃ£o Linear

Principais mÃ©tricas:

RÂ² treino: 0.887

RÂ² validaÃ§Ã£o: 0.830

DiferenÃ§a: 0.056 â†’ sem overfitting

VisualizaÃ§Ãµes:

Predito vs Real

DistribuiÃ§Ã£o dos resÃ­duos

Salvamento:

models/baseline_model.pkl

ğŸ“ EntregÃ¡veis:

notebooks/03_Modelo_Baseline.ipynb

models/baseline_model.pkl

models/predicoes_vs_real.png

models/residuos.png

-------------------------------------------------------------

âš™ï¸ Etapa 4 â€” OtimizaÃ§Ã£o e Tuning de HiperparÃ¢metros

Objetivo: melhorar o desempenho do modelo usando tÃ©cnicas de otimizaÃ§Ã£o e validaÃ§Ã£o avanÃ§ada.

âœ”ï¸ O que foi feito

Modelo escolhido para otimizaÃ§Ã£o:
ğŸ‘‰ Random Forest Regressor (mais robusto e adequado que a RegressÃ£o Linear)

TÃ©cnica de tuning:
ğŸ‘‰ RandomizedSearchCV
(mais rÃ¡pido, eficiente e ideal para muitos hiperparÃ¢metros)

HiperparÃ¢metros otimizados:

NÃºmero de Ã¡rvores (n_estimators)

Profundidade mÃ¡xima (max_depth)

min_samples_split

min_samples_leaf

bootstrap

ValidaÃ§Ã£o:

Cross-Validation (5 folds)

Treinamento final:

Modelo final treinado usando treino + validaÃ§Ã£o

Apenas depois foi testado no conjunto de teste real

AvaliaÃ§Ã£o final no conjunto de teste:

MAE, RMSE e RÂ² calculados

Resultados mostraram desempenho superior ao modelo baseline

VisualizaÃ§Ãµes:

GrÃ¡fico Predito vs Real

DistribuiÃ§Ã£o dos resÃ­duos

AnÃ¡lise dos erros extremos (maiores diferenÃ§as)

Salvamento do modelo:

models/modelo_final.pkl

ğŸ“ EntregÃ¡veis:

notebooks/04_Otimizacao.ipynb

models/modelo_final.pkl

GrÃ¡ficos de avaliaÃ§Ã£o final