ğŸ“Š Etapa 1 â€” AnÃ¡lise ExploratÃ³ria de Dados (EDA)

Projeto de Machine Learning â€“ Entendimento dos Dados

ğŸ¯ VisÃ£o Geral

Na Etapa 1, o objetivo foi explorar, compreender e visualizar o dataset bruto para identificar problemas, padrÃµes, distribuiÃ§Ãµes e relaÃ§Ãµes entre variÃ¡veis.
Essa fase Ã© fundamental para orientar o que serÃ¡ feito no prÃ©-processamento (Etapa 2) e na modelagem (Etapa 3).

Todo o trabalho foi documentado no notebook:
ğŸ“ notebooks/01_Analise_Exploratoria.ipynb

ğŸ“ Tarefas Realizadas
1ï¸âƒ£ Carregamento e InspeÃ§Ã£o Inicial
âœ”ï¸ O que foi feito:

Carregamento do dataset bruto.

VisualizaÃ§Ã£o das primeiras linhas e dos tipos de dados.

AnÃ¡lise de:

NÃºmero de linhas e colunas

Tipos das variÃ¡veis (numÃ©ricas, categÃ³ricas, datas, texto)

EstatÃ­sticas gerais com .describe()

ğŸ¯ Objetivo: entender a estrutura do dataset e identificar possÃ­veis problemas logo de inÃ­cio.

2ï¸âƒ£ AnÃ¡lise de Valores Faltantes
âœ”ï¸ O que foi feito:

IdentificaÃ§Ã£o de colunas com valores ausentes (NaN).

QuantificaÃ§Ã£o do total de valores faltantes por coluna e porcentagem afetada.

VisualizaÃ§Ã£o grÃ¡fica (quando necessÃ¡rio) para destacar gravidade e impacto.

ğŸ¯ ImportÃ¢ncia: valores faltantes serÃ£o tratados apenas na Etapa 2, mas aqui foi fundamental detectar onde, quanto e por quÃª isso acontece.

3ï¸âƒ£ AnÃ¡lise EstatÃ­stica das VariÃ¡veis NumÃ©ricas
âœ”ï¸ O que foi feito:

Histograma para cada variÃ¡vel numÃ©rica.

Boxplots para identificaÃ§Ã£o de:

DistribuiÃ§Ã£o

Assimetria

PresenÃ§a de outliers

CÃ¡lculo de medidas importantes:

MÃ©dia

Mediana

Desvio padrÃ£o

Quartis

ğŸ¯ Objetivo: entender o comportamento das variÃ¡veis, localizar outliers e possÃ­veis transformaÃ§Ãµes necessÃ¡rias.

4ï¸âƒ£ AnÃ¡lise das VariÃ¡veis CategÃ³ricas
âœ”ï¸ O que foi feito:

Contagem de categorias (value_counts).

GrÃ¡ficos de barras mostrando a frequÃªncia de cada categoria.

VerificaÃ§Ã£o da qualidade das categorias:

InconsistÃªncias

Categorias muito raras

Erros de digitaÃ§Ã£o

ğŸ¯ Objetivo: mapear categorias antes de aplicar encoding na Etapa 2.

5ï¸âƒ£ CorrelaÃ§Ã£o Entre VariÃ¡veis
âœ”ï¸ O que foi feito:

Matriz de correlaÃ§Ã£o entre variÃ¡veis numÃ©ricas.

Heatmap para visualizar relaÃ§Ãµes fortes e fracas.

IdentificaÃ§Ã£o de:

VariÃ¡veis redundantes

PossÃ­veis features importantes para o modelo

ğŸ¯ Objetivo: entender como variÃ¡veis se relacionam entre si e prever impacto na modelagem.

6ï¸âƒ£ GeraÃ§Ã£o dos GrÃ¡ficos Principais (somente os mais importantes)

O professor pediu apenas os grÃ¡ficos essenciais, entÃ£o os principais incluÃ­dos foram:

ğŸ“ˆ Histograma de variÃ¡veis mais relevantes

ğŸ“¦ Boxplot destacando outliers importantes

ğŸ“Š GrÃ¡fico de barras das categorias mais significativas

ğŸ”¥ Heatmap com as correlaÃ§Ãµes principais

ğŸ¯ Esses grÃ¡ficos serviram para comprovar visualmente que a exploraÃ§Ã£o foi realizada corretamente.

ğŸ“ EntregÃ¡veis
Arquivo	DescriÃ§Ã£o
ğŸ““ notebooks/01_Analise_Exploratoria.ipynb	Notebook completo com anÃ¡lises e grÃ¡ficos
ğŸ“ data/raw/*	Dataset bruto utilizado
ğŸ¤ ApresentaÃ§Ã£o (4â€“5 Minutos)
ğŸ–¼ï¸ Slide 1 â€” VisÃ£o Geral do Dataset

Quantidade de linhas e colunas

Tipos de variÃ¡veis

ğŸ§© Slide 2 â€” Problemas Identificados

Valores faltantes

Outliers

InconsistÃªncias

ğŸ“Š Slide 3 â€” Principais GrÃ¡ficos

Histogramas essenciais

Boxplot mais relevante

Heatmap de correlaÃ§Ãµes

ğŸ“Œ Slide 4 â€” ConclusÃ£o

O que foi aprendido sobre os dados

PreparaÃ§Ã£o para Etapa 2 (limpeza e transformaÃ§Ã£o)

âœ… Checklist de Sucesso

 Dataset carregado e analisado com clareza

 Valores faltantes identificados

 Outliers mapeados

 VariÃ¡veis categÃ³ricas entendidas

 CorrelaÃ§Ãµes visualizadas

 GrÃ¡ficos principais gerados e revisados

ğŸš€ ConclusÃ£o

A Etapa 1 forneceu entendimento profundo dos dados, revelando problemas e padrÃµes cruciais para o prÃ©-processamento.
Agora, com essa anÃ¡lise completa, foi possÃ­vel seguir para a Etapa 2 com seguranÃ§a, limpando e preparando os dados da forma correta.

ğŸ“¦ Etapa 2 â€” PrÃ©-Processamento de Dados
Projeto de Machine Learning â€“ PreparaÃ§Ã£o dos Dados

ğŸ¯ VisÃ£o Geral
Nesta etapa, realizamos a limpeza, transformaÃ§Ã£o e padronizaÃ§Ã£o dos dados brutos analisados na Etapa 1.
O objetivo Ã© deixar o dataset pronto para treinar modelos de Machine Learning, garantindo qualidade, consistÃªncia e formato adequado.
Todo o trabalho desta etapa estÃ¡ documentado no notebook:
ğŸ“ notebooks/02_Preprocessamento.ipynb

ğŸ“ Tarefas Realizadas
1ï¸âƒ£ Tratamento de Valores Faltantes
Por que fazer isso?
â¡ï¸ Algoritmos de Machine Learning nÃ£o lidam com NaN. Deixar valores faltantes gera erros e prejudica o modelo.
âœ”ï¸ O que foi feito:


Colunas numÃ©ricas: valores imputados usando mediana (mais segura contra outliers).

Colunas categÃ³ricas: preenchimento com a categoria mais frequente.

2ï¸âƒ£ Tratamento de Outliers
Por que fazer isso?
â¡ï¸ Outliers distorcem escalas, atrapalham modelos lineares e podem influenciar negativamente os resultados.
âœ”ï¸ O que foi feito:


Outliers foram identificados com base na anÃ¡lise da Etapa 1.


Aplicada a tÃ©cnica de capping (limite pelo IQR) para reduzir impacto sem remover dados importantes.


RemoÃ§Ã£o apenas de valores claramente incorretos (quando identificado como erro de digitaÃ§Ã£o/mediÃ§Ã£o).



3ï¸âƒ£ Encoding de VariÃ¡veis CategÃ³ricas
Por que fazer isso?
â¡ï¸ Modelos de ML nÃ£o entendem texto. Precisamos converter para nÃºmeros.
âœ”ï¸ O que foi feito:


One-Hot Encoding aplicado para variÃ¡veis categÃ³ricas nominais.


Utilizado drop_first=True para evitar multicolinearidade.


VariÃ¡veis com ordem natural (ordinais) foram codificadas com mapeamento numÃ©rico apropriado.



4ï¸âƒ£ NormalizaÃ§Ã£o das VariÃ¡veis NumÃ©ricas
Por que fazer isso?
â¡ï¸ Colunas em escalas muito diferentes podem fazer o modelo priorizar algumas features sem necessidade.
âœ”ï¸ O que foi feito:


Aplicado StandardScaler (mÃ©dia 0 e desvio padrÃ£o 1) apÃ³s limpeza completa.


O scaler foi salvo para uso futuro:
ğŸ“ models/scaler.pkl



5ï¸âƒ£ Feature Engineering (Opcional)
Por que fazer isso?
â¡ï¸ Novas features podem ajudar o modelo a aprender padrÃµes mais profundos.
âœ”ï¸ O que foi criado:


Features derivadas de relaÃ§Ãµes entre variÃ¡veis (exemplo: velocidade mÃ©dia, razÃµes entre colunas etc. â€” adapte conforme seu projeto).


Cada feature criada foi documentada e justificada no notebook.



ğŸ“Š EntregÃ¡veis Principais
ArquivoDescriÃ§Ã£oğŸ““ notebooks/02_Preprocessamento.ipynbCÃ³digo + explicaÃ§Ãµes da etapağŸ“ data/students_clean.csvDataset final tratadoâš™ï¸ models/scaler.pklScaler salvo para uso na modelagem

ğŸ¤ ApresentaÃ§Ã£o (4â€“5 Minutos)
ğŸ–¼ï¸ Slide 1 â€” Problemas Corrigidos


Quantidade de valores faltantes tratados


Outliers identificados e qual estratÃ©gia foi usada


ğŸ§© Slide 2 â€” Principais TransformaÃ§Ãµes


Exemplo de One-Hot Encoding


ComparaÃ§Ã£o de variÃ¡veis antes/depois da normalizaÃ§Ã£o


ğŸ› ï¸ Slide 3 â€” Feature Engineering


Novas features criadas


MotivaÃ§Ã£o e impacto esperado


ğŸ“Š Slide 4 â€” Resultado Final


DimensÃµes antes e depois


ConfirmaÃ§Ã£o de que o dataset estÃ¡ pronto para modelagem



âœ… Checklist de Sucesso


 Notebook organizado com seÃ§Ãµes claras


 Justificativas detalhadas em Markdown


 Dataset final salvo corretamente


 Scaler salvo em models/scaler.pkl


 Notebook executa do inÃ­cio ao fim sem erros


ğŸš€ ConclusÃ£o
A Etapa 2 garante que os dados estejam consistentes, completos e padronizados â€” prontos para avanÃ§armos para a etapa de modelagem na fase 3!


# ğŸ“Š Etapa 3 â€” Modelo Baseline (RegressÃ£o Linear)
Projeto de Machine Learning â€“ ConstruÃ§Ã£o do Primeiro Modelo

## ğŸ¯ VisÃ£o Geral

Na Etapa 3, construÃ­mos nosso **primeiro modelo de Machine Learning** â€” um baseline usando **RegressÃ£o Linear**. 
Este modelo servirÃ¡ como referÃªncia para comparar com modelos mais complexos no futuro.

O objetivo Ã©:
- âœ”ï¸ Treinar um modelo simples e interpretÃ¡vel
- âœ”ï¸ Avaliar desempenho com mÃ©tricas padrÃ£o
- âœ”ï¸ Detectar problemas como overfitting
- âœ”ï¸ Compreender quais variÃ¡veis mais impactam a previsÃ£o

Todo o trabalho desta etapa estÃ¡ documentado no notebook:
ğŸ“ **notebooks/03_Modelo_Baseline.ipynb**

---

## ğŸ“ Tarefas Realizadas

### 1ï¸âƒ£ Carregamento dos Dados Limpos

**Por que fazer isso?**
â¡ï¸ Usamos os dados jÃ¡ processados da Etapa 2, garantindo qualidade e consistÃªncia.

**âœ”ï¸ O que foi feito:**

- Carregamento do arquivo `delivery_clean.csv` gerado na Etapa 2
- VerificaÃ§Ã£o de integridade (formas, tipos de dados)
- ConfirmaÃ§Ã£o de que nÃ£o hÃ¡ valores faltantes

---

### 2ï¸âƒ£ PreparaÃ§Ã£o das Features (X) e Target (y)

**Por que fazer isso?**
â¡ï¸ Precisamos separar variÃ¡veis de entrada (features) da variÃ¡vel que queremos prever (target).

**âœ”ï¸ O que foi feito:**

- **Target (y):** `delivery_time_hours` â€” o que o modelo vai prever
- **Features (X):** todas as outras colunas relevantes
- RemoÃ§Ã£o de IDs e colunas nÃ£o Ãºteis (`delivery_id`)
- SincronizaÃ§Ã£o entre X e y para garantir consistÃªncia

---

### 3ï¸âƒ£ CodificaÃ§Ã£o de VariÃ¡veis CategÃ³ricas

**Por que fazer isso?**
â¡ï¸ A RegressÃ£o Linear sÃ³ funciona com nÃºmeros. VariÃ¡veis texto precisam ser convertidas.

**âœ”ï¸ O que foi feito:**

- IdentificaÃ§Ã£o de colunas categÃ³ricas (texto)
- AplicaÃ§Ã£o de **One-Hot Encoding** com `pd.get_dummies()`
- Uso de `drop_first=True` para evitar multicolinearidade (armadilha de dummy)
- Resultado: features aumentaram de X colunas para Y colunas (mais features binÃ¡rias)

---

### 4ï¸âƒ£ Tratamento de Valores Faltantes (NaN)

**Por que fazer isso?**
â¡ï¸ RegressÃ£o Linear nÃ£o aceita NaN nativamente e gera erros.

**âœ”ï¸ O que foi feito:**

- VerificaÃ§Ã£o de NaN por coluna apÃ³s codificaÃ§Ã£o
- **RemoÃ§Ã£o de linhas com valores faltantes** (mantÃ©m consistÃªncia)
- SincronizaÃ§Ã£o: quando removemos linhas de X, removemos as mesmas de y
- Resultado: dataset limpo e pronto para treinamento

---

### 5ï¸âƒ£ DivisÃ£o dos Dados (Train / Validation / Test)

**Por que fazer isso?**
â¡ï¸ Precisamos de dados separados para:
- **Treinar** o modelo
- **Validar** durante desenvolvimento
- **Testar** de forma imparcial no final

**âœ”ï¸ O que foi feito:**

- **60% Treino** (X_train, y_train) â€” dados para ajustar os pesos do modelo
- **20% ValidaÃ§Ã£o** (X_val, y_val) â€” dados para avaliar e ajustar hiperparÃ¢metros
- **20% Teste** (X_test, y_test) â€” dados **guardados** para avaliaÃ§Ã£o final (NÃƒO USAR AGORA)

**MÃ©todo:** 
1. Separar 20% para teste
2. Do restante, separar 25% para validaÃ§Ã£o (25% de 80% = 20% do total)

---

### 6ï¸âƒ£ Treinamento do Modelo Baseline

**Por que RegressÃ£o Linear?**
â¡ï¸ Ã‰ simples, rÃ¡pido, interpretÃ¡vel e fornece uma boa linha de base para comparaÃ§Ã£o.

**âœ”ï¸ O que foi feito:**

```python
from sklearn.linear_model import LinearRegression

modelo = LinearRegression()
modelo.fit(X_train, y_train)
```

- Ajuste dos coeficientes Î² para minimizar o erro quadrÃ¡tico
- O modelo aprendeu a relaÃ§Ã£o linear entre features e target
- **Resultado:** Modelo treinado pronto para fazer previsÃµes

---

### 7ï¸âƒ£ AnÃ¡lise dos Coeficientes (Feature Importance)

**Por que fazer isso?**
â¡ï¸ Entender quais variÃ¡veis mais impactam a previsÃ£o de tempo de entrega.

**âœ”ï¸ O que foi feito:**

- ExtraÃ§Ã£o dos coeficientes do modelo
- Ranking das features por impacto (valor absoluto)
- **Top 5 VariÃ¡veis Mais Impactantes** identificadas
- InterpretaÃ§Ã£o: coeficientes positivos aumentam o tempo, negativos diminuem

**Exemplo de saÃ­da:**
```
Feature                  Coeficiente
distance_km              3.45
package_weight_kg        0.82
shipping_class_Standard -0.50
...
```

---

### 8ï¸âƒ£ AvaliaÃ§Ã£o e MÃ©tricas

**Por que fazer isso?**
â¡ï¸ Quantificar o desempenho do modelo com mÃ©tricas padrÃ£o e detectar problemas.

**âœ”ï¸ MÃ©tricas Calculadas:**

| MÃ©trica | O que significa | FÃ³rmula | Melhor valor |
|---------|-----------------|---------|--------------|
| **MSE** | Erro QuadrÃ¡tico MÃ©dio | MÃ©dia de (y - Å·)Â² | PrÃ³ximo de 0 |
| **RMSE** | Raiz do MSE | âˆšMSE | PrÃ³ximo de 0 |
| **MAE** | Erro Absoluto MÃ©dio | MÃ©dia de \|y - Å·\| | PrÃ³ximo de 0 |
| **RÂ²** | Coeficiente de DeterminaÃ§Ã£o | 1 - (SS_res / SS_tot) | PrÃ³ximo de 1 |

**âœ”ï¸ O que foi feito:**

- PrevisÃµes em Treino: `y_train_pred = modelo.predict(X_train)`
- PrevisÃµes em ValidaÃ§Ã£o: `y_val_pred = modelo.predict(X_val)`
- CÃ¡lculo de MSE, RMSE, MAE e RÂ² para ambos os conjuntos
- **ComparaÃ§Ã£o Treino vs ValidaÃ§Ã£o** em tabela clara

**Exemplo de saÃ­da:**
```
          MSE      RMSE     MAE      RÂ²
Treino    2.34     1.53    0.98    0.87
ValidaÃ§Ã£o 2.67     1.63    1.05    0.84
```

---

### 9ï¸âƒ£ DetecÃ§Ã£o de Overfitting

**Por que fazer isso?**
â¡ï¸ Overfitting ocorre quando o modelo memoriza treino mas falha em dados novos.

**âœ”ï¸ O que foi feito:**

- CÃ¡lculo da diferenÃ§a de RÂ² entre Treino e ValidaÃ§Ã£o
- **AnÃ¡lise:** 
  - DiferenÃ§a < 0.10 â†’ âœ… Modelo generaliza bem
  - DiferenÃ§a > 0.10 â†’ âš ï¸ PossÃ­vel overfitting

**Exemplo:**
```
DiferenÃ§a RÂ²: 0.03 â†’ âœ… SUCESSO: Modelo generaliza bem (sem overfitting grave)
```

---

### ğŸ”Ÿ VisualizaÃ§Ãµes

**Por que fazer isso?**
â¡ï¸ GrÃ¡ficos facilitam entendimento visual do desempenho.

**âœ”ï¸ O que foi feito:**

#### **GrÃ¡fico 1: Predito vs Real (Scatter Plot)**
- Eixo X: Valores reais de tempo de entrega
- Eixo Y: PrevisÃµes do modelo
- Linha vermelha: previsÃ£o perfeita (y = x)
- InterpretaÃ§Ã£o: quanto mais prÃ³ximo da linha, melhor o modelo
- Salvo em: `models/predicoes_vs_real.png`

#### **GrÃ¡fico 2: DistribuiÃ§Ã£o de ResÃ­duos (Histogram)**
- ResÃ­duos = Erro (Real - Previsto)
- DistribuiÃ§Ã£o ideal: simÃ©trica e centrada em zero
- PresenÃ§a de cauda pesada pode indicar outliers
- Salvo em: `models/residuos.png`

---

### 1ï¸âƒ£1ï¸âƒ£ Salvamento do Modelo

**Por que fazer isso?**
â¡ï¸ Reutilizar o modelo em produÃ§Ã£o sem treinar novamente.

**âœ”ï¸ O que foi feito:**

```python
import joblib

joblib.dump(modelo, 'models/baseline_model.pkl')
```

- Modelo serializado e salvo
- Pode ser carregado depois com: `joblib.load('models/baseline_model.pkl')`
- LocalizaÃ§Ã£o: `ğŸ“ models/baseline_model.pkl`

---

## ğŸ“Š EntregÃ¡veis Principais

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| ğŸ““ `notebooks/03_Modelo_Baseline.ipynb` | CÃ³digo + explicaÃ§Ãµes do treinamento |
| ğŸ“ `models/baseline_model.pkl` | Modelo treinado salvo |
| ğŸ“ˆ `models/predicoes_vs_real.png` | GrÃ¡fico Predito vs Real |
| ğŸ“‰ `models/residuos.png` | DistribuiÃ§Ã£o de resÃ­duos |

---

## ğŸ¤ ApresentaÃ§Ã£o (4â€“5 Minutos)

### ğŸ–¼ï¸ Slide 1 â€” VisÃ£o Geral do Modelo

- Tipo: RegressÃ£o Linear (Baseline)
- Dados: 2510 amostras, X features apÃ³s encoding
- DivisÃ£o: 60% treino, 20% validaÃ§Ã£o, 20% teste

### ğŸ§© Slide 2 â€” Processo de PreparaÃ§Ã£o

- CodificaÃ§Ã£o de categorias (One-Hot Encoding)
- Tratamento de NaN
- DivisÃ£o estratÃ©gica dos dados

### ğŸ“Š Slide 3 â€” MÃ©tricas e Desempenho

- Tabela comparativa Treino vs ValidaÃ§Ã£o
- RÂ² do modelo
- DiferenÃ§a de RÂ² (anÃ¡lise de overfitting)
- **ConclusÃ£o:** Modelo generaliza bem? HÃ¡ overfitting?

### ğŸ” Slide 4 â€” Top Features e InterpretaÃ§Ã£o

- 5 variÃ¡veis mais impactantes
- Qual aumenta/diminui tempo de entrega?
- Faz sentido com o negÃ³cio?

### ğŸ“ˆ Slide 5 â€” GrÃ¡ficos Principais

- Predito vs Real (scatter plot)
- DistribuiÃ§Ã£o de resÃ­duos

---

## âœ… Checklist de Sucesso

- âœ”ï¸ Dados carregados e preparados sem erros
- âœ”ï¸ Features codificadas (One-Hot Encoding aplicado)
- âœ”ï¸ NaN tratados apropriadamente
- âœ”ï¸ Dados divididos em treino/validaÃ§Ã£o/teste
- âœ”ï¸ Modelo treinado com sucesso
- âœ”ï¸ MÃ©tricas calculadas (MSE, RMSE, MAE, RÂ²)
- âœ”ï¸ Overfitting analisado
- âœ”ï¸ GrÃ¡ficos gerados e salvos
- âœ”ï¸ Modelo salvo em `.pkl`
- âœ”ï¸ Notebook executa do inÃ­cio ao fim sem erros

---

## ğŸš€ PrÃ³ximos Passos

Agora que temos um modelo baseline:

1. **Etapa 4 (Modelos AvanÃ§ados):** Testar Random Forest, XGBoost, etc.
2. **Ajustes:** Tuning de hiperparÃ¢metros
3. **ValidaÃ§Ã£o Final:** Avaliar no conjunto de teste
4. **Deploy:** Colocar o melhor modelo em produÃ§Ã£o

---

## ğŸ“ ConclusÃ£o

A Etapa 3 estabeleceu uma **linha de base sÃ³lida** com RegressÃ£o Linear. 
Este modelo simples e interpretÃ¡vel serve como referÃªncia para futuras melhorias e fornece insights sobre quais features impactam mais o tempo de entrega.

**Com essa estrutura, estamos prontos para avanÃ§ar para modelagem mais sofisticada!** ğŸš€